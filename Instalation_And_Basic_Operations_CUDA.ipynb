{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_Operations_CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8d4jO9HPHfiMNbNQ1/Ds0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dyfox100/CUDA-Tutorials/blob/main/Instalation_And_Basic_Operations_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXOBPs-1NIj9",
        "outputId": "a9123232-9769-4922-a212-e9de540fe12c"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cThW-266NOje",
        "outputId": "84b3fede-89ed-4309-a4b9-9e1e7d55b141"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-7mmw36en\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-7mmw36en\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=bc5ae87ea90011f77ebb35107ba8a66b6b73c750d5e6e5470a740e78b81b6509\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ptejcnrc/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcAqEBx2QHfj",
        "outputId": "85eeadd4-1954-493e-f574-a07f22f95e68"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aRUAcuWQUEO",
        "outputId": "129fc43f-1750-45b8-d76b-70cbdda1f280"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*just to check if the extension is working. None of his runs on the gpu.*/\n",
        "int main() {\n",
        "    printf(\"If this prints, the CUDA etension works!\\n\");\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If this prints, the CUDA etension works!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1LOgyrbOPn3",
        "outputId": "7ad0eac2-a67a-4479-fb92-37bc891cb3b8"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Device function to calculate power value. It runs on GPU.\n",
        "__global__ void power(int *p, int *q, int *r){\n",
        "    *r = (*p)*(*q);\n",
        "}\n",
        "\n",
        "// Host function to call device function. It runs on CPU.\n",
        "int main(){\n",
        "    \n",
        "    // Host copies of variables\n",
        "    int p, q, r;\n",
        "\n",
        "    // Device copies of variables\n",
        "    int *device_p, *device_q, *device_r;\n",
        "\n",
        "   \n",
        "    int size = sizeof(int);\n",
        "\n",
        "    // Allocate space for device copies\n",
        "    cudaMalloc((void **)&device_p, size);\n",
        "    cudaMalloc((void **)&device_q, size);\n",
        "    cudaMalloc((void **)&device_r, size);\n",
        "\n",
        "    // Fix the input variable values\n",
        "    r = 1;\n",
        "    p = 3;\n",
        "    q = 5;\n",
        "\n",
        "    // Copy input variables to device\n",
        "\n",
        "    cudaMemcpy(device_p, &p, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMemcpy(device_q, &q, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch power kernel\n",
        "\n",
        "    power<<<1,1>>>(device_p, device_q, device_r);\n",
        "\n",
        "    // Copy the result back to the host\n",
        "\n",
        "    cudaError err = cudaMemcpy(&r, device_r, size, cudaMemcpyDeviceToHost);\n",
        "    if(err!=cudaSuccess) {\n",
        "        printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "    if(err!=cudaSuccess) {\n",
        "          printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "\n",
        "    printf(\"result is %d\\n\",r);\n",
        "\n",
        "    // Cleanup\n",
        "\n",
        "    cudaFree(device_p);\n",
        "    cudaFree(device_q);\n",
        "    cudaFree(device_r);\n",
        "    return 0;\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result is 15\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx9L3_99OVa-"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}