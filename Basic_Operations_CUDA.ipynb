{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_Operations_CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPY//j8seV7xV0wm9WqQvrz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dyfox100/CUDA-Tutorials/blob/main/Basic_Operations_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVtqLvSvUZsx"
      },
      "source": [
        "Double check to see if the CUDA compiler is installed and updated. The !(bang) operator in jupyter notebooks runs shell commands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXOBPs-1NIj9",
        "outputId": "0f7a0ea7-1a35-4c3e-fef5-d2ca9df0ff39"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8q__nulU0Hi"
      },
      "source": [
        "Installs the nvcc_plugin needed to run CUDA C/C++ from notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cThW-266NOje",
        "outputId": "7c93ab6a-05be-4183-b6da-cc67a0ea8556"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9wagm3n8\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9wagm3n8\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=4130c8f522fb13eefc727d13f218fc889ec443571d17b8c38f8440628d5bb2f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n38gk02k/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMq6bCrYU6_S"
      },
      "source": [
        "Starts extension running in jupyter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcAqEBx2QHfj",
        "outputId": "986f95bc-e121-49df-f420-be1da3e02184"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAJDi96XU70C"
      },
      "source": [
        "Simple program to make sure the C/C++ CUDA extension works. This won't run on gpu, but if the extension isn't working, colab will try to run this in python and it will blow up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aRUAcuWQUEO",
        "outputId": "1d579178-a1bf-482b-ffdd-a57acc50d075"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*just to check if the extension is working. None of his runs on the gpu.*/\n",
        "int main() {\n",
        "    printf(\"If this prints, the CUDA etension works!\\n\");\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If this prints, the CUDA etension works!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnfbUoQyU8gx"
      },
      "source": [
        "Basic copy to gpu and add kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1LOgyrbOPn3",
        "outputId": "35940d8b-2478-4dbf-e086-e3eb90984352"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "// Simple gpu function to add two variables.\n",
        "__global__ void add(int *a, int *b, int *r){\n",
        "    *r = *a + *b;\n",
        "}\n",
        "\n",
        "// Main function to run the gpu code.\n",
        "int main() { \n",
        "    int a, b, r;\n",
        "\n",
        "    // gpu copies\n",
        "    int *g_a, *g_b, *g_r;\n",
        "\n",
        "    // Allocates space on gpu for the three ints.\n",
        "    // Puts pointers to this space in the variables g_a, g_b, g_r.\n",
        "    cudaMalloc((void **)&g_a, sizeof(int));\n",
        "    cudaMalloc((void **)&g_b, sizeof(int));\n",
        "    cudaMalloc((void **)&g_r, sizeof(int));\n",
        "\n",
        "   a = 2;\n",
        "   b = 5;\n",
        "\n",
        "    // Copy variables to gpu.\n",
        "    cudaMemcpy(g_a, &a, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(g_b, &b, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel on gpu.\n",
        "\n",
        "    add<<<1,1>>>(g_a, g_b, g_r);\n",
        "\n",
        "    // Copy the result back to the host and check for errors in copy.\n",
        "    cudaError err = cudaMemcpy(&r, g_r, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    if(err!=cudaSuccess) {\n",
        "        printf(\"Error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "\n",
        "    printf(\"Adding %d with %d on the gpu yields %d\\n\",a, b, r);\n",
        "\n",
        "    // Need to free memory on gpu.\n",
        "    cudaFree(g_a);\n",
        "    cudaFree(g_b);\n",
        "    cudaFree(g_r);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adding 2 with 5 on the gpu yields 7\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx9L3_99OVa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf81448-b309-4821-c376-9498e8fd8245"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void hello_cuda() {\n",
        "    printf(\"Hello from CUDA!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // kernel launch params. First is num of blocks. Second is num threads in block.\n",
        "    // Should print 6 times, 3 threads per block on 2 blocks.\n",
        "    // Can use dim3 type to get 3d initilization of threads /blocks.\n",
        "    // Should be less than 1024 threads in x,y and 64 threads in z. And x * y * z must be less than 1024.\n",
        "    // Must be less than 65536 thread blocks in y and z dirs and 2^32 - 1 in x.  \n",
        "    dim3 block(3, 1, 1);\n",
        "    dim3 grid(2, 1, 1);\n",
        "    hello_cuda <<<grid, block>>>();\n",
        "    // Waits until kernel completes. Necessary because main function will finish\n",
        "    // before the kernel prints otherwise.\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello from CUDA!\n",
            "Hello from CUDA!\n",
            "Hello from CUDA!\n",
            "Hello from CUDA!\n",
            "Hello from CUDA!\n",
            "Hello from CUDA!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SrA5Fg3cYDW"
      },
      "source": [
        "Grid and block \n",
        "\n",
        "Grid -- The collection of all threads in a kernel. \n",
        "\n",
        "Block -- Threads in a grid are organized into a block. \n",
        "\n",
        "The variables threadIdx, blockIdx, blockDim, and gridDim can provide us with information about the gird/blocks/threads. \n",
        "\n",
        "Note that each thread runs independently, so the output is intermingled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iKc3mT8eZfk",
        "outputId": "aa2e396d-4962-4266-98a1-d9ca828deba3"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void print_thread_id() {\n",
        "    // Kernels have access to threadIDx structs that identify threads in a block.\n",
        "    printf(\"Thread ID is: (%d, %d, %d)\\n\", threadIdx.x, threadIdx.y, threadIdx.z);\n",
        "    // Also have access to blockIdx which identifys blocks in the grid.\n",
        "    printf(\"Block ID is: (%d, %d, %d)\\n\", blockIdx.x, blockIdx.y, blockIdx.z);\n",
        "    // blockDim structs hold the number of threads in each block. Same for all\n",
        "    // blocks / threads.\n",
        "    printf(\"Each block has %d by %d by %d blocks.\\n\",\n",
        "           blockDim.x, blockDim.y, blockDim.x);\n",
        "    // There is also a gridDim struct which gives dimensions of the grid (in number of blocks).\n",
        "    printf(\"The grid has %d by %d by %d blocks.\\n\", \n",
        "           gridDim.x, gridDim.y, gridDim.z);\n",
        "    // We can use this info to get the total number of threads.\n",
        "    printf(\"The total number of threads is: %d.\\n\", \n",
        "           (blockDim.x * blockDim.y * blockDim.z) * (gridDim.x * gridDim.y * gridDim.z));\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    dim3 block(2, 1, 1);\n",
        "    dim3 grid(2, 2, 1);\n",
        "    print_thread_id <<<grid, block>>>();\n",
        "    // Waits until kernel completes. Necessary because main function will finish\n",
        "    // before the kernel prints otherwise.\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread ID is: (0, 0, 0)\n",
            "Thread ID is: (1, 0, 0)\n",
            "Thread ID is: (0, 0, 0)\n",
            "Thread ID is: (1, 0, 0)\n",
            "Thread ID is: (0, 0, 0)\n",
            "Thread ID is: (1, 0, 0)\n",
            "Thread ID is: (0, 0, 0)\n",
            "Thread ID is: (1, 0, 0)\n",
            "Block ID is: (0, 1, 0)\n",
            "Block ID is: (0, 1, 0)\n",
            "Block ID is: (1, 1, 0)\n",
            "Block ID is: (1, 1, 0)\n",
            "Block ID is: (1, 0, 0)\n",
            "Block ID is: (1, 0, 0)\n",
            "Block ID is: (0, 0, 0)\n",
            "Block ID is: (0, 0, 0)\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "Each block has 2 by 1 by 2 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The grid has 2 by 2 by 1 blocks.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "The total number of threads is: 8.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBLcq2Af1hW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}